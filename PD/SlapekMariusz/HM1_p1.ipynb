{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (part I)\n",
    "## Author: Mariusz SÅ‚apek\n",
    "## Case study 1\n",
    "## Date: 31.03.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This raport contains the results of research on repreduction of 3 articles about Python packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seglearn: A Python Package for Learning Sequences and Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links:\n",
    "1. paper: http://www.jmlr.org/papers/volume19/18-160/18-160.pdf  \n",
    "2. github: https://github.com/dmbee/seglearn  \n",
    "3. webpage: https://dmbee.github.io/seglearn/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*seglearn* is an open-source Python package for performing machine learning on time series or sequences. The implementation provides a flexible pipeline for tackling classification, regression, and forecasting problems with multivariate sequence and contextual data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7823878069432684\n"
     ]
    }
   ],
   "source": [
    "import seglearn as sgl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = sgl.load_watch()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"X\"], data[\"y\"])\n",
    "\n",
    "clf = sgl.Pype([(\"seg\", sgl.SegmentX(width=100, overlap=0.5)),\n",
    "                (\"features\", sgl.FeatureRep()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"rf\", RandomForestClassifier())])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(\"accuracy score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from seglearn.datasets import load_watch\n",
    "from seglearn.base import TS_Data\n",
    "\n",
    "def test_ts_data():\n",
    "    # time series data\n",
    "    ts = np.array([np.random.rand(100, 10), np.random.rand(200, 10), np.random.rand(20, 10)])\n",
    "    c = np.random.rand(3, 10)\n",
    "    data = TS_Data(ts, c)\n",
    "\n",
    "    assert np.array_equal(data.context_data, c)\n",
    "    assert np.all([np.array_equal(data.ts_data[i], ts[i]) for i in range(len(ts))])\n",
    "    assert isinstance(data[1], TS_Data)\n",
    "    assert np.array_equal(data[1].ts_data, ts[1])\n",
    "    assert np.array_equal(data[1].context_data, c[1])\n",
    "\n",
    "    # segmented time series data\n",
    "\n",
    "    sts = np.random.rand(100, 10, 6)\n",
    "    c = np.random.rand(100, 6)\n",
    "\n",
    "    data = TS_Data(sts, c)\n",
    "    assert isinstance(data[4:10], TS_Data)\n",
    "    assert np.array_equal(data[4:10].ts_data, sts[4:10])\n",
    "    assert np.array_equal(data[4:10].context_data, c[4:10])\n",
    "\n",
    "    sts = np.random.rand(100, 10)\n",
    "    c = np.random.rand(100)\n",
    "\n",
    "    data = TS_Data(sts, c)\n",
    "    assert isinstance(data[4:10], TS_Data)\n",
    "    assert np.array_equal(data[4:10].ts_data, sts[4:10])\n",
    "    assert np.array_equal(data[4:10].context_data, c[4:10])\n",
    "\n",
    "def test_watch():\n",
    "    df = load_watch()\n",
    "    data = TS_Data(df['X'], df['side'])\n",
    "    assert isinstance(data, TS_Data)\n",
    "\n",
    "\n",
    "def test_pd():\n",
    "    ts = np.array([np.random.rand(100, 10), np.random.rand(200, 10), np.random.rand(20, 10)])\n",
    "    c = np.random.rand(3, 10)\n",
    "\n",
    "    df = pd.DataFrame(c)\n",
    "    df['ts_data'] = ts\n",
    "    data = TS_Data.from_df(df)\n",
    "\n",
    "    assert np.all([np.array_equal(data.ts_data[i], ts[i]) for i in range(len(ts))])\n",
    "    assert np.array_equal(data.context_data, c)\n",
    "\n",
    "    \n",
    "test_ts_data()\n",
    "test_watch()    \n",
    "test_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error\n",
    "\n",
    "In file requirements.txt we have only a info that a package *scipy* is necessary, but there is no version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.stats' has no attribute 'median_absolute_deviation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\WB1 WB1\\HM1.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muvf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mtest_mv_feature_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mtest_uv_feature_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\WB1 WB1\\HM1.ipynb\u001b[0m in \u001b[0;36mtest_mv_feature_functions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mftr_funcs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mmvf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mftr_funcs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmv_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmvf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\seglearn\\feature_functions.py\u001b[0m in \u001b[0;36mmedian_absolute_deviation\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmedian_absolute_deviation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;34m''' median absolute deviation for each variable in a segmented time series '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian_absolute_deviation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.stats' has no attribute 'median_absolute_deviation'"
     ]
    }
   ],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from seglearn import feature_functions\n",
    "\n",
    "\n",
    "def test_mv_feature_functions():\n",
    "    ''' test feature functions with multivariate data '''\n",
    "\n",
    "    # sliding window data is shape [n_segments, width, variables]\n",
    "    N = 20\n",
    "    W = 30\n",
    "    mv_data = np.random.rand(N, W, 3)\n",
    "\n",
    "    ftr_funcs = {}\n",
    "    ftr_funcs.update(feature_functions.all_features())\n",
    "    ftr_funcs.update(feature_functions.base_features())\n",
    "    ftr_funcs.update(feature_functions.hudgins_features())\n",
    "    ftr_funcs.update(feature_functions.emg_features())\n",
    "\n",
    "    for f in ftr_funcs:\n",
    "        mvf = ftr_funcs[f](mv_data)\n",
    "        assert len(mvf) == N\n",
    "\n",
    "\n",
    "def test_uv_feature_functions():\n",
    "    ''' test feature functions with univariate data '''\n",
    "    N = 20\n",
    "    W = 30\n",
    "    uv_data = np.random.rand(N, W)\n",
    "\n",
    "    ftr_funcs = {}\n",
    "    ftr_funcs.update(feature_functions.all_features())\n",
    "    ftr_funcs.update(feature_functions.base_features())\n",
    "    ftr_funcs.update(feature_functions.hudgins_features())\n",
    "    ftr_funcs.update(feature_functions.emg_features())\n",
    "\n",
    "    for f in ftr_funcs:\n",
    "        uvf = ftr_funcs[f](uv_data)\n",
    "        assert len(uvf) == N\n",
    "        \n",
    "test_mv_feature_functions()\n",
    "test_uv_feature_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from seglearn.pipe import Pype\n",
    "from seglearn.transform import FeatureRep, SegmentX, SegmentXY, SegmentXYForecast, PadTrunc\n",
    "from seglearn.base import TS_Data\n",
    "\n",
    "\n",
    "def yvals(y):\n",
    "    if len(np.atleast_1d(y[0])) > 1:\n",
    "        return np.unique(np.concatenate(y))\n",
    "    else:\n",
    "        return np.unique(y)\n",
    "\n",
    "\n",
    "def transformation_test(clf, X, y):\n",
    "    clf.fit(X, y)\n",
    "    Xtr1, ytr1 = clf.transform(X, y)\n",
    "    Xtr2, ytr2 = clf.fit_transform(X, y)\n",
    "    assert np.all(Xtr1 == Xtr2)\n",
    "    assert np.all(ytr1 == ytr2)\n",
    "    assert np.all(np.isin(np.unique(ytr1), yvals(y)))\n",
    "    assert len(Xtr1) == len(ytr1)\n",
    "\n",
    "\n",
    "def test_pipe_transformation():\n",
    "    # SegmentX transform pipe\n",
    "    pipe = Pype([('seg', SegmentX()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('scaler', StandardScaler())])\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [1, 2, 3]\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    # SegmentXY transform pipe\n",
    "    pipe = Pype([('seg', SegmentXY()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('scaler', StandardScaler())])\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [np.random.rand(1000), np.random.rand(100), np.random.rand(500)]\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    # Forecast transform pipe\n",
    "    pipe = Pype([('seg', SegmentXYForecast()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('scaler', StandardScaler())])\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [np.random.rand(1000), np.random.rand(100), np.random.rand(500)]\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    # Padtrunc transform pipe\n",
    "    pipe = Pype([('trunc', PadTrunc()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('scaler', StandardScaler())])\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [1, 2, 3]\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    transformation_test(pipe, X, y)\n",
    "\n",
    "\n",
    "def classifier_test(clf, X, y):\n",
    "    yv = yvals(y)\n",
    "    clf.fit(X, y)\n",
    "    yp = clf.predict(X)\n",
    "    ytr, yp2 = clf.transform_predict(X, y)\n",
    "    assert np.all(np.isin(np.unique(ytr), yv))\n",
    "    assert len(ytr) == len(yp2)\n",
    "    assert np.all(np.isin(np.unique(yp2), yv))\n",
    "    assert np.all(yp == yp2)\n",
    "    pp = clf.predict_proba(X)\n",
    "    assert pp.shape[0] == len(yp)\n",
    "    assert pp.shape[1] == len(yv)\n",
    "    score = clf.score(X, y)\n",
    "    assert score <= 1.0 and score >= 0.0\n",
    "\n",
    "    if clf._get_segmenter():\n",
    "        s = clf.predict_segmented_series(X, categorical_target=True)\n",
    "        for i in np.arange(len(X)):\n",
    "            assert len(X[i]) == len(s[i])\n",
    "            assert np.all(np.isin(np.unique(s[i]), yv))\n",
    "\n",
    "\n",
    "def test_pipe_classification():\n",
    "    # no context data, single time series\n",
    "    X = [np.random.rand(1000, 10)]\n",
    "    y = [5]\n",
    "\n",
    "    pipe = Pype([('seg', SegmentX()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('rf', RandomForestClassifier(n_estimators=10))])\n",
    "\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    # context data, single time seres\n",
    "    Xt = [np.random.rand(1000, 10)]\n",
    "    Xc = [np.random.rand(3)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [5]\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    # multiple time series\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [1, 2, 3]\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    # univariate data\n",
    "    Xt = [np.random.rand(1000), np.random.rand(100), np.random.rand(500)]\n",
    "    Xc = np.random.rand(3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [1, 2, 3]\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "\n",
    "def regression_test(clf, X, y):\n",
    "    yv = yvals(y)\n",
    "    clf.fit(X, y)\n",
    "    yp = clf.predict(X)\n",
    "    ytr, yp2 = clf.transform_predict(X, y)\n",
    "    assert np.all(np.isin(np.unique(ytr), yv))\n",
    "    assert len(ytr) == len(yp2)\n",
    "    assert np.all(yp == yp2)\n",
    "    score = clf.score(X, y)\n",
    "    assert score <= 1.0 and score >= 0.0\n",
    "\n",
    "    if clf._get_segmenter():\n",
    "        s = clf.predict_segmented_series(X, categorical_target=False)\n",
    "        for i in np.arange(len(X)):\n",
    "            assert len(X[i]) == len(s[i])\n",
    "            assert np.max(yp) >= np.max(s[i])\n",
    "            assert np.min(yp) <= np.min(s[i])\n",
    "\n",
    "\n",
    "def test_pipe_regression():\n",
    "    # no context data, single time series\n",
    "    X = [np.random.rand(1000, 10)]\n",
    "    y = [np.random.rand(1000)]\n",
    "    pipe = Pype([('seg', SegmentXY()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('ridge', Ridge())])\n",
    "    regression_test(pipe, X, y)\n",
    "\n",
    "    # context data, single time seres\n",
    "    Xt = [np.random.rand(1000, 10)]\n",
    "    Xc = [np.random.rand(3)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [np.random.rand(1000)]\n",
    "    regression_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    regression_test(pipe, X, y)\n",
    "\n",
    "    # multiple time seres\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [np.random.rand(1000), np.random.rand(100), np.random.rand(500)]\n",
    "    regression_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    regression_test(pipe, X, y)\n",
    "\n",
    "    # cross val\n",
    "    Xt = np.array([np.random.rand(1000, 10)] * 5)\n",
    "    Xc = np.random.rand(5, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = np.array([np.random.rand(1000)] * 5)\n",
    "    cross_validate(pipe, X, y, cv=3)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    Xt = [np.random.rand(1000, 10)] * 5\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "\n",
    "    cross_validate(pipe, X, y, cv=3)\n",
    "\n",
    "\n",
    "def forecast_test(clf, X, y):\n",
    "    yv = yvals(y)\n",
    "    clf.fit(X, y)\n",
    "    yp = clf.predict(X)\n",
    "    ytr, yp2 = clf.transform_predict(X, y)\n",
    "    assert np.all(np.isin(np.unique(ytr), yv))\n",
    "    assert len(ytr) == len(yp2)\n",
    "    assert np.all(yp == yp2)\n",
    "    score = clf.score(X, y)\n",
    "    assert score <= 1.0 and score >= 0.0\n",
    "\n",
    "\n",
    "def test_pipe_forecast():\n",
    "    # no context data, single time series\n",
    "    X = [np.random.rand(1000, 10)]\n",
    "    y = [np.random.rand(1000)]\n",
    "\n",
    "    pipe = Pype([('seg', SegmentXYForecast()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "    forecast_test(pipe, X, y)\n",
    "\n",
    "    # context data, single time seres\n",
    "    Xt = [np.random.rand(1000, 10)]\n",
    "    Xc = [np.random.rand(3)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [np.random.rand(1000)]\n",
    "\n",
    "    forecast_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    forecast_test(pipe, X, y)\n",
    "\n",
    "    # multiple time seres\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [np.random.rand(1000), np.random.rand(100), np.random.rand(500)]\n",
    "\n",
    "    forecast_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    forecast_test(pipe, X, y)\n",
    "\n",
    "    # cross val\n",
    "\n",
    "    Xt = np.array([np.random.rand(1000, 10)] * 5)\n",
    "    Xc = np.random.rand(5, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = np.array([np.random.rand(1000)] * 5)\n",
    "\n",
    "    cross_validate(pipe, X, y, cv=3)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    Xt = [np.random.rand(1000, 10)] * 5\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    cross_validate(pipe, X, y, cv=3)\n",
    "\n",
    "\n",
    "def test_pipe_PadTrunc():\n",
    "    # no context data, single time series\n",
    "    X = [np.random.rand(1000, 10)]\n",
    "    y = [5]\n",
    "    pipe = Pype([('trunc', PadTrunc()),\n",
    "                 ('ftr', FeatureRep()),\n",
    "                 ('rf', RandomForestClassifier(n_estimators=10))])\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    # context data, single time seres\n",
    "    Xt = [np.random.rand(1000, 10)]\n",
    "    Xc = [np.random.rand(3)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [5]\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    # multiple time series\n",
    "    Xt = [np.random.rand(1000, 10), np.random.rand(100, 10), np.random.rand(500, 10)]\n",
    "    Xc = np.random.rand(3, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [1, 2, 3]\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    # univariate data\n",
    "    Xt = [np.random.rand(1000), np.random.rand(100), np.random.rand(500)]\n",
    "    Xc = np.random.rand(3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [1, 2, 3]\n",
    "    classifier_test(pipe, X, y)\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xt\n",
    "    X = TS_Data.from_df(X)\n",
    "    classifier_test(pipe, X, y)\n",
    "    \n",
    "test_pipe_transformation()\n",
    "test_pipe_classification()\n",
    "test_pipe_regression()\n",
    "test_pipe_forecast()\n",
    "test_pipe_PadTrunc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from seglearn.preprocessing import TargetRunLengthEncoder\n",
    "from seglearn.base import TS_Data\n",
    "\n",
    "from seglearn.util import get_ts_data_parts\n",
    "\n",
    "def test_trle():\n",
    "\n",
    "    # Multivariate data\n",
    "    Nt = 100\n",
    "    nvars = 5\n",
    "    X = [np.random.rand(Nt, nvars)]\n",
    "    y = [np.concatenate([np.full(3, 1), np.full(26, 2), np.full(1, 3), np.full(70, 4)])]\n",
    "\n",
    "    rle = TargetRunLengthEncoder(min_length=5)\n",
    "    rle.fit(X)\n",
    "    Xt, yt, _ = rle.transform(X, y)\n",
    "\n",
    "    assert len(Xt) == len(yt) and len(yt) == 2\n",
    "    assert yt[0] == 2 and yt[1] == 4\n",
    "    assert len(Xt[0]) == 26 and len(Xt[1]) == 70\n",
    "\n",
    "    # Nothing excluded\n",
    "    Nt = 100\n",
    "    nvars = 5\n",
    "    X = [np.random.rand(Nt, nvars)]\n",
    "    y = [np.concatenate([np.full(50,1), np.full(50,2)])]\n",
    "\n",
    "    rle = TargetRunLengthEncoder(min_length=5)\n",
    "    rle.fit(X, y)\n",
    "    Xt, yt, _ = rle.transform(X, y)\n",
    "\n",
    "    assert len(Xt) == len(yt) and len(yt) == 2\n",
    "    assert np.all(np.concatenate(Xt) == X)\n",
    "    assert yt[0] == 1 and yt[1] == 2\n",
    "    assert len(Xt[0]) == 50 and len(Xt[1]) == 50\n",
    "\n",
    "    # Univariate data with sample weight and context\n",
    "    Nt = 100\n",
    "    Xts = [np.random.rand(Nt)]\n",
    "    Xc = [5]\n",
    "    X = TS_Data(Xts, Xc)\n",
    "    y = [np.concatenate([np.full(3, 1), np.full(26, 2), np.full(1, 3), np.full(70, 4)])]\n",
    "    sw = [1]\n",
    "\n",
    "    rle = TargetRunLengthEncoder(min_length=5)\n",
    "    rle.fit(X)\n",
    "    Xt, yt, swt = rle.transform(X, y, sw)\n",
    "    Xtc = Xt.context_data\n",
    "\n",
    "    assert len(Xt) == len(yt) and len(swt) == len(yt) and len(yt) == 2\n",
    "    assert yt[0] == 2 and yt[1] == 4\n",
    "    assert len(Xt[0]) == 26 and len(Xt[1]) == 70\n",
    "    assert swt[0] == 1 and swt[1] == 1\n",
    "    assert Xtc[0] == 5 and Xtc[1] == 5\n",
    "\n",
    "    X = pd.DataFrame(Xc)\n",
    "    X['ts_data'] = Xts\n",
    "    X = TS_Data.from_df(X)\n",
    "\n",
    "    rle = TargetRunLengthEncoder(min_length=5)\n",
    "    rle.fit(X)\n",
    "    Xt, yt, swt = rle.transform(X, y, sw)\n",
    "    Xtc = Xt.context_data\n",
    "\n",
    "    assert len(Xt) == len(yt) and len(swt) == len(yt) and len(yt) == 2\n",
    "    assert yt[0] == 2 and yt[1] == 4\n",
    "    assert len(Xt[0]) == 26 and len(Xt[1]) == 70\n",
    "    assert swt[0] == 1 and swt[1] == 1\n",
    "    assert Xtc[0] == 5 and Xtc[1] == 5\n",
    "\n",
    "    \n",
    "test_trle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "from numpy.random import rand\n",
    "import numpy as np\n",
    "\n",
    "from seglearn.split import TemporalKFold, temporal_split\n",
    "from seglearn.base import TS_Data\n",
    "\n",
    "\n",
    "def test_temporal_split():\n",
    "    # test with length 1 series\n",
    "    X = [rand(100, 10)]\n",
    "    y = [5]\n",
    "    Xtr, Xte, ytr, yte = temporal_split(X, y)\n",
    "    check_split(X, Xtr, Xte, y, ytr, yte)\n",
    "\n",
    "    X = [rand(100, 10)]\n",
    "    y = [rand(100)]\n",
    "    Xtr, Xte, ytr, yte = temporal_split(X, y)\n",
    "    check_split(X, Xtr, Xte, y, ytr, yte)\n",
    "\n",
    "    Xt = [rand(100, 10)]\n",
    "    Xc = [5]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [rand(100)]\n",
    "    Xtr, Xte, ytr, yte = temporal_split(X, y)\n",
    "    check_split(X, Xtr, Xte, y, ytr, yte)\n",
    "\n",
    "    # test with lots of series\n",
    "    Ns = 5\n",
    "    X = np.array([rand(100, 10)] * Ns)\n",
    "    y = rand(Ns)\n",
    "    Xtr, Xte, ytr, yte = temporal_split(X, y)\n",
    "    check_split(X, Xtr, Xte, y, ytr, yte)\n",
    "\n",
    "    X = np.array([rand(100, 10)] * Ns)\n",
    "    y = np.array([rand(100)] * Ns)\n",
    "    Xtr, Xte, ytr, yte = temporal_split(X, y)\n",
    "    check_split(X, Xtr, Xte, y, ytr, yte)\n",
    "\n",
    "    Xt = np.array([rand(100, 10)] * Ns)\n",
    "    Xc = rand(Ns)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = np.arange(Ns)\n",
    "    Xtr, Xte, ytr, yte = temporal_split(X, y)\n",
    "    check_split(X, Xtr, Xte, y, ytr, yte)\n",
    "\n",
    "\n",
    "def test_temporal_k_fold():\n",
    "    # test length 1 series\n",
    "    splitter = TemporalKFold()\n",
    "    X = [rand(100, 10)]\n",
    "    y = [5]\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "    X = [rand(100, 10)]\n",
    "    y = [rand(100)]\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "    Xt = [rand(100, 10)]\n",
    "    Xc = [5]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = [rand(100)]\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "    # test with lots of series\n",
    "    splitter = TemporalKFold()\n",
    "    Ns = 5\n",
    "    X = np.array([rand(100, 10)] * Ns)\n",
    "    y = rand(Ns)\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "    X = np.array([rand(100, 10)] * Ns)\n",
    "    y = np.array([rand(100)] * Ns)\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "    Xt = np.array([rand(100, 10)] * Ns)\n",
    "    Xc = rand(Ns)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = np.array([rand(100)] * Ns)\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "    Xt = np.array([rand(100, 10)] * Ns)\n",
    "    Xc = rand(Ns)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = rand(Ns)\n",
    "    Xs, ys, cv = splitter.split(X, y)\n",
    "    check_folds(Xs, ys, cv)\n",
    "\n",
    "\n",
    "def check_ts_var(X, Xtr, Xte):\n",
    "    assert np.all([np.array_equal(np.concatenate((Xtr[i], Xte[i])), X[i]) for i in range(len(X))])\n",
    "\n",
    "\n",
    "def check_static_var(y, ytr, yte):\n",
    "    assert np.array_equal(np.array(y), np.array(ytr))\n",
    "    assert np.array_equal(np.array(y), np.array(yte))\n",
    "\n",
    "\n",
    "def check_split(X, Xtr, Xte, y, ytr, yte):\n",
    "    assert len(Xtr) == len(ytr)\n",
    "    assert len(Xte) == len(yte)\n",
    "\n",
    "    if isinstance(X, TS_Data):\n",
    "        assert isinstance(Xtr, TS_Data)\n",
    "        assert isinstance(Xte, TS_Data)\n",
    "        Xt = X.ts_data\n",
    "        Xtrt = Xtr.ts_data\n",
    "        Xtet = Xte.ts_data\n",
    "        Xc = X.context_data\n",
    "        Xtrc = Xtr.context_data\n",
    "        Xtec = Xte.context_data\n",
    "        check_static_var(Xc, Xtrc, Xtec)\n",
    "        check_ts_var(Xt, Xtrt, Xtet)\n",
    "    else:\n",
    "        check_ts_var(X, Xtr, Xte)\n",
    "\n",
    "    if len(np.atleast_1d(y[0])) > 1:\n",
    "        check_ts_var(y, ytr, yte)\n",
    "    else:\n",
    "        check_static_var(y, ytr, yte)\n",
    "\n",
    "\n",
    "def check_folds(Xs, ys, cv):\n",
    "    idj = []\n",
    "    for i in range(len(cv)):\n",
    "        assert len(Xs[cv[i][0]]) == len(ys[cv[i][0]])\n",
    "        assert len(Xs[cv[i][1]]) == len(ys[cv[i][1]])\n",
    "        idi = np.concatenate((cv[i][0], cv[i][1]))\n",
    "        assert np.array_equal(np.sort(idi), np.arange(len(idi)))  # checks each value in fold\n",
    "        idj.append(cv[i][1])\n",
    "    idj = np.concatenate(idj)\n",
    "    assert np.array_equal(np.sort(idj), np.arange(len(idj)))  # checks each value tested once\n",
    "    \n",
    "    \n",
    "test_temporal_split()\n",
    "test_temporal_k_fold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test transform "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "import pytest\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seglearn.transform as transform\n",
    "from seglearn.base import TS_Data\n",
    "from seglearn.feature_functions import all_features, mean\n",
    "from seglearn.util import get_ts_data_parts\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def test_sliding_window():\n",
    "    N = 1000\n",
    "    width = 10\n",
    "    ts = np.random.rand(N)\n",
    "    for step in 1 + np.arange(width):\n",
    "        sts = transform.sliding_window(ts, width, step)\n",
    "        sts_c = transform.sliding_window(ts, width, step, 'C')\n",
    "        assert sts.flags.f_contiguous and sts_c.flags.c_contiguous\n",
    "        assert sts.shape[1] == width and sts_c.shape[1] == width\n",
    "        Nsts = 1 + (N - width) // step\n",
    "        assert Nsts == sts.shape[0] and Nsts == sts_c.shape[0]\n",
    "        assert np.all(np.isin(sts, ts)) and np.all(np.isin(sts_c, ts))\n",
    "\n",
    "        # reconstruct the ts\n",
    "        if step == 1:\n",
    "            assert np.array_equal(np.concatenate((sts[:, 0], sts[-1, 1:width])), ts)\n",
    "            assert np.array_equal(np.concatenate((sts_c[:, 0], sts_c[-1, 1:width])), ts)\n",
    "\n",
    "        if step == width:\n",
    "            assert np.array_equal(sts.ravel(), ts)\n",
    "            assert np.array_equal(sts_c.ravel(), ts)\n",
    "\n",
    "\n",
    "def test_sliding_tensor():\n",
    "    N = 1000\n",
    "    V = 5\n",
    "    width = 10\n",
    "    ts = np.random.rand(N, V)\n",
    "    for step in 1 + np.arange(width):\n",
    "        sts = transform.sliding_tensor(ts, width, step)\n",
    "        assert sts.shape[1] == width\n",
    "        assert sts.shape[2] == V\n",
    "        Nsts = 1 + (N - width) // step\n",
    "        assert Nsts == sts.shape[0]\n",
    "        for j in range(V):\n",
    "            assert np.all(np.isin(sts[:, :, j], ts[:, j]))\n",
    "\n",
    "        # todo: reconstruct tensor ts\n",
    "\n",
    "    final_tensor = []\n",
    "    for step in 1 + np.arange(width):\n",
    "        sts = transform.sliding_tensor(ts, width, step, 'C')\n",
    "        final_tensor.append(sts)\n",
    "        assert sts.flags.c_contiguous\n",
    "        assert sts.shape[1] == width\n",
    "        assert sts.shape[2] == V\n",
    "        Nsts = 1 + (N - width) // step\n",
    "        assert Nsts == sts.shape[0]\n",
    "        for j in range(V):\n",
    "            assert np.all(np.isin(sts[:, :, j], ts[:, j]))\n",
    "    assert np.concatenate(final_tensor).flags.c_contiguous\n",
    "\n",
    "def test_feature_rep():\n",
    "    # multivariate ts\n",
    "    frep = transform.FeatureRep(features=all_features())\n",
    "    X = np.random.rand(100, 10, 5)\n",
    "    y = np.ones(100)\n",
    "    frep.fit(X, y)\n",
    "    Xt = frep.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(frep.f_labels) == Xt.shape[1]\n",
    "\n",
    "    # univariate ts\n",
    "    X = np.random.rand(100, 10)\n",
    "    y = np.ones(100)\n",
    "    frep.fit(X, y)\n",
    "    Xt = frep.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(frep.f_labels) == Xt.shape[1]\n",
    "\n",
    "    # single feature\n",
    "    frep = transform.FeatureRep(features={'mean': mean})\n",
    "    frep.fit(X, y)\n",
    "    Xt = frep.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(frep.f_labels) == Xt.shape[1]\n",
    "    assert Xt.shape[1] == 1\n",
    "\n",
    "    # ts with multivariate contextual data\n",
    "    frep = transform.FeatureRep(features=all_features())\n",
    "    X = TS_Data(np.random.rand(100, 10, 5), np.random.rand(100, 3))\n",
    "    y = np.ones(100)\n",
    "    frep.fit(X, y)\n",
    "    Xt = frep.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(frep.f_labels) == Xt.shape[1]\n",
    "\n",
    "    # ts with univariate contextual data\n",
    "    X = TS_Data(np.random.rand(100, 10, 5), np.random.rand(100))\n",
    "    y = np.ones(100)\n",
    "    frep.fit(X, y)\n",
    "    Xt = frep.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(frep.f_labels) == Xt.shape[1]\n",
    "\n",
    "\n",
    "def test_segmentx():\n",
    "    # test illegal parameter settings\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentX(width=0)                  # illegal width value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentX(overlap=None, step=None)  # either overlap or step must be defined\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentX(overlap=-1, step=None)    # illegal overlap value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentX(step=0)                   # illegal step value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentX(order=None)               # illegal order\n",
    "\n",
    "    # test _step property working as expected\n",
    "    seg = transform.SegmentX(width=10, overlap=0.5)\n",
    "    assert seg._step == 5\n",
    "\n",
    "    # test precedence of step over overlap\n",
    "    seg = transform.SegmentX(width=10, overlap=1, step=1)\n",
    "    assert seg._step == 1\n",
    "\n",
    "    # illegal overlap value, but valid step value\n",
    "    seg = transform.SegmentX(overlap=-1, step=1)\n",
    "    assert seg._step == 1\n",
    "\n",
    "    # test shape of segmented data\n",
    "    width = 5\n",
    "    nvars = 5\n",
    "    seg = transform.SegmentX(width=width)\n",
    "\n",
    "    # multivariate ts data without context data\n",
    "    X = [np.random.rand(100, nvars), np.random.rand(100, nvars), np.random.rand(100, nvars)]\n",
    "    y = np.random.rand(3)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width, nvars)\n",
    "\n",
    "    # univariate ts data without context\n",
    "    X = [np.random.rand(100), np.random.rand(100), np.random.rand(100)]\n",
    "    y = np.random.rand(3)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width)\n",
    "\n",
    "    # multivariate ts data with context data\n",
    "    Xt = [np.random.rand(100, nvars), np.random.rand(200, nvars), np.random.rand(50, nvars)]\n",
    "    Xc = np.random.rand(3, 4)\n",
    "    y = np.random.rand(3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 4)\n",
    "\n",
    "    # ts data with univariate context data\n",
    "    Xt = [np.random.rand(100), np.random.rand(200), np.random.rand(50)]\n",
    "    Xc = np.random.rand(3)\n",
    "    y = np.random.rand(3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width)\n",
    "    assert Xsc.shape == (N, 1)\n",
    "\n",
    "    # same number as context vars and time vars\n",
    "    # this would cause broadcasting failure before implementation of TS_Data class\n",
    "    Xt = [np.random.rand(100, nvars), np.random.rand(200, nvars), np.random.rand(50, nvars)]\n",
    "    Xc = np.random.rand(3, nvars)\n",
    "    y = np.random.rand(3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 5)\n",
    "\n",
    "\n",
    "def test_segmentxy():\n",
    "    # test illegal parameter settings\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXY(width=0)                  # illegal width value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXY(overlap=None, step=None)  # either overlap or step must be defined\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXY(overlap=-1, step=None)    # illegal overlap value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXY(step=0)                   # illegal step value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXY(order=None)               # illegal order\n",
    "\n",
    "    # test _step property working as expected\n",
    "    seg = transform.SegmentXY(width=10, overlap=0.5)\n",
    "    assert seg._step == 5\n",
    "\n",
    "    # test precedence of step over overlap\n",
    "    seg = transform.SegmentXY(width=10, overlap=1, step=1)\n",
    "    assert seg._step == 1\n",
    "\n",
    "    # illegal overlap value, but valid step value\n",
    "    seg = transform.SegmentXY(overlap=-1, step=1)\n",
    "    assert seg._step == 1\n",
    "\n",
    "    # test shape of segmented data\n",
    "    Nt = 100\n",
    "    width = 5\n",
    "    nvars = 5\n",
    "    seg = transform.SegmentXY(width=width)\n",
    "\n",
    "    # multivariate ts data without context data\n",
    "    X = [np.random.rand(Nt, nvars), np.random.rand(Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    y = [np.random.rand(Nt), np.random.rand(Nt), np.random.rand(Nt)]\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width, nvars)\n",
    "\n",
    "    # univariate ts data without context data\n",
    "    X = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(3 * Nt)]\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(3 * Nt)]\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width)\n",
    "\n",
    "    # multivariate ts data with context data\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3, 4)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 4)\n",
    "\n",
    "    # ts data with univariate context data\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 1)\n",
    "\n",
    "    # same number as context vars and time vars\n",
    "    # this would cause broadcasting failure before implementation of TS_Data class\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3, nvars)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 5)\n",
    "\n",
    "\n",
    "def test_segmentxyforecast():\n",
    "    # test illegal parameter settings\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXYForecast(width=0)                  # illegal width value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXYForecast(overlap=None, step=None)  # either overlap or step must be defined\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXYForecast(overlap=-1, step=None)    # illegal overlap value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXYForecast(step=0)                   # illegal step value\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXYForecast(order=None)               # illegal order\n",
    "    with pytest.raises(ValueError):\n",
    "        transform.SegmentXYForecast(forecast=0)               # illegal forecast value\n",
    "\n",
    "    # test _step property working as expected\n",
    "    seg = transform.SegmentXYForecast(width=10, overlap=0.5)\n",
    "    assert seg._step == 5\n",
    "\n",
    "    # test precedence of step over overlap\n",
    "    seg = transform.SegmentXYForecast(width=10, overlap=1, step=1)\n",
    "    assert seg._step == 1\n",
    "\n",
    "    # illegal overlap value, but valid step value\n",
    "    seg = transform.SegmentXYForecast(overlap=-1, step=1)\n",
    "    assert seg._step == 1\n",
    "\n",
    "    # test shape of segmented data\n",
    "    Nt = 100\n",
    "    width = 5\n",
    "    nvars = 5\n",
    "\n",
    "    # lets do a forecast test\n",
    "    seg = transform.SegmentXYForecast(width=width, forecast=5)\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3, 4)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 4)\n",
    "\n",
    "    # univariate X\n",
    "    nvars = 1\n",
    "    seg = transform.SegmentXYForecast(width=width, forecast=5)\n",
    "    X = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width)\n",
    "\n",
    "\n",
    "def test_pad_trunc():\n",
    "    Nt = 100\n",
    "    width = 5\n",
    "    nvars = 5\n",
    "    seg = transform.PadTrunc(width=width)\n",
    "\n",
    "    # multivariate ts data without context data\n",
    "    X = [np.random.rand(Nt, nvars), np.random.rand(Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    y = [np.random.rand(Nt), np.random.rand(Nt), np.random.rand(Nt)]\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width, nvars)\n",
    "    assert np.all([np.equal(X[i][0:width], Xs[i]) for i in range(len(X))])\n",
    "    assert np.all([np.equal(y[i][0:width], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    # univariate ts data without context data\n",
    "    X = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(3 * Nt)]\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(3 * Nt)]\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width)\n",
    "    assert np.all([np.equal(X[i][0:width], Xs[i]) for i in range(len(X))])\n",
    "    assert np.all([np.equal(y[i][0:width], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    # multivariate ts data with context data\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3, 4)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 4)\n",
    "    assert np.all([np.equal(Xt[i][0:width], Xst[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(Xc[i], Xsc[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(y[i][0:width], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    # ts data with univariate context data\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N,)\n",
    "    assert np.all([np.equal(Xt[i][0:width], Xst[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(Xc[i], Xsc[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(y[i][0:width], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    # same number as context vars and time vars\n",
    "    # this would cause broadcasting failure before implementation of TS_Data class\n",
    "    Xt = [np.random.rand(Nt, nvars), np.random.rand(2 * Nt, nvars), np.random.rand(Nt, nvars)]\n",
    "    Xc = np.random.rand(3, nvars)\n",
    "    y = [np.random.rand(Nt), np.random.rand(2 * Nt), np.random.rand(Nt)]\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 5)\n",
    "    assert np.all([np.equal(Xt[i][0:width], Xst[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(Xc[i], Xsc[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(y[i][0:width], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    width = 5\n",
    "    nvars = 5\n",
    "    seg = transform.PadTrunc(width=width)\n",
    "\n",
    "    # multivariate ts data without context data\n",
    "    X = [np.random.rand(100, nvars), np.random.rand(100, nvars), np.random.rand(100, nvars)]\n",
    "    y = np.random.rand(3)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width, nvars)\n",
    "    assert np.all([np.equal(X[i][0:width], Xs[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(y[i], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    # univariate ts data without context\n",
    "    X = [np.random.rand(100), np.random.rand(100), np.random.rand(100)]\n",
    "    y = np.random.rand(3)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    N = len(ys)\n",
    "    assert Xs.shape == (N, width)\n",
    "    assert np.all([np.equal(X[i][0:width], Xs[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(y[i], ys[i]) for i in range(len(y))])\n",
    "\n",
    "    # multivariate ts data with context data\n",
    "    Xt = [np.random.rand(100, nvars), np.random.rand(200, nvars), np.random.rand(50, nvars)]\n",
    "    Xc = np.random.rand(3, 4)\n",
    "    y = np.random.rand(3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    seg.fit(X, y)\n",
    "    Xs, ys, _ = seg.transform(X, y)\n",
    "    Xst, Xsc = get_ts_data_parts(Xs)\n",
    "    N = len(ys)\n",
    "    assert Xst.shape == (N, width, nvars)\n",
    "    assert Xsc.shape == (N, 4)\n",
    "    assert np.all([np.equal(Xt[i][0:width], Xst[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(Xc[i], Xsc[i]) for i in range(len(Xt))])\n",
    "    assert np.all([np.equal(y[i], ys[i]) for i in range(len(y))])\n",
    "\n",
    "\n",
    "def test_interp():\n",
    "    # univariate time series\n",
    "    N = 100\n",
    "    t = np.arange(N) + np.random.rand(N)\n",
    "    X = [np.column_stack([t, np.random.rand(N)])]\n",
    "    y = [np.random.rand(N)]\n",
    "\n",
    "    interp = transform.Interp(2)\n",
    "    interp.fit(X)\n",
    "    Xc, yc, swt = interp.transform(X, y)\n",
    "\n",
    "    assert len(Xc[0]) == N / 2\n",
    "    assert len(yc[0]) == N / 2\n",
    "    assert np.ndim(Xc[0]) == 1\n",
    "\n",
    "    y = [np.random.randint(0, 5, N)]\n",
    "    interp = transform.Interp(5, kind='cubic', categorical_target=True)\n",
    "    interp.fit(X, y)\n",
    "    Xc, yc, swt = interp.transform(X, y)\n",
    "\n",
    "    assert len(Xc[0]) == N / 5\n",
    "    assert len(yc[0]) == N / 5\n",
    "    assert np.ndim(Xc[0]) == 1\n",
    "    assert np.all(np.isin(yc, np.arange(6)))\n",
    "\n",
    "    # multivariate time series\n",
    "    N = 100\n",
    "    D = 5\n",
    "    t = np.arange(N) + np.random.rand(N)\n",
    "    X = [np.column_stack([t, np.random.rand(N,D)])]\n",
    "    y = [np.random.rand(N)]\n",
    "\n",
    "    interp = transform.Interp(2)\n",
    "    interp.fit(X)\n",
    "    Xc, yc, swt = interp.transform(X, y)\n",
    "\n",
    "    assert len(Xc[0]) == N / 2\n",
    "    assert len(yc[0]) == N / 2\n",
    "    assert Xc[0].shape[1] == D\n",
    "\n",
    "    y = [np.random.randint(0, 5, N)]\n",
    "    interp = transform.Interp(5, kind='cubic', categorical_target=True)\n",
    "    interp.fit(X, y)\n",
    "    Xc, yc, swt = interp.transform(X, y)\n",
    "\n",
    "    assert len(Xc[0]) == N / 5\n",
    "    assert len(yc[0]) == N / 5\n",
    "    assert Xc[0].shape[1] == D\n",
    "    assert np.all(np.isin(yc, np.arange(6)))\n",
    "\n",
    "    # sorting case\n",
    "    N = 100\n",
    "    t = np.arange(N)\n",
    "    t[0:3] = 0\n",
    "    X = [np.column_stack([t, np.random.rand(N)])]\n",
    "    y = [np.random.rand(N)]\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        interp = transform.Interp(sample_period=2, assume_sorted=False)\n",
    "        interp.fit(X)\n",
    "        Xc, yc, swt = interp.transform(X, y)\n",
    "        assert len(w) == 2\n",
    "        assert issubclass(w[-1].category, UserWarning)\n",
    "        assert \"duplicate\" in str(w[-1].message)\n",
    "        assert len(Xc[0]) == N / 2\n",
    "        assert len(yc[0]) == N / 2\n",
    "        assert np.ndim(Xc[0]) == 1\n",
    "        assert np.count_nonzero(np.isnan(Xc)) == 0\n",
    "\n",
    "\n",
    "def test_interp_long_to_wide():\n",
    "    # Test 1\n",
    "    t = np.array([1.1, 1.2, 2.1, 3.3, 3.4, 3.5]).astype(float)\n",
    "    s = np.array([0, 1, 0, 0, 1, 1]).astype(float)\n",
    "    v1 = np.array([3, 4, 5, 7, 15, 25]).astype(float)\n",
    "    v2 = np.array([5, 7, 6, 9, 22, 35]).astype(float)\n",
    "    y = np.array([1, 2, 2, 2, 3, 3]).astype(float)\n",
    "    df = np.column_stack([t, s, v1, v2])\n",
    "\n",
    "    X = [df, df]\n",
    "    y = [y, y]\n",
    "    \n",
    "    stacked_interp = transform.InterpLongToWide(0.5)\n",
    "    stacked_interp.fit(X, y)\n",
    "    Xc, yc, swt = stacked_interp.transform(X, y)\n",
    "\n",
    "    # --Checks--\n",
    "    # linearly sampled time within bounds = 1.2, 1.7, 2.2, 2.7, 3.2 --> len(Xc[0]) = 5\n",
    "    assert len(Xc[0]) == 5\n",
    "    # Xc shape[1] = unique(s) * no. dimensions of values (V1) = 2 * 2 = 4\n",
    "    assert Xc[0].shape[1] == 4\n",
    "    assert swt is None\n",
    "\n",
    "    # Test 2\n",
    "    y = [1, 2]\n",
    "    stacked_interp.fit(X, y)\n",
    "    Xc, yc, swt = stacked_interp.transform(X, y)\n",
    "    assert np.array_equal(yc, y)\n",
    "\n",
    "    # Test 3\n",
    "    N = 100\n",
    "    sample_period = 0.5\n",
    "    t = np.arange(N) + np.random.rand(N)\n",
    "    s = np.array([1, 2] * int(N/2))\n",
    "    np.random.shuffle(s)\n",
    "\n",
    "    v1 = np.arange(N) + np.random.rand(N)\n",
    "    v2 = np.arange(N) + np.random.rand(N)\n",
    "    v3 = np.arange(N) + np.random.rand(N)\n",
    "    df = np.column_stack([t, s, v1, v2, v3])\n",
    "    X = [df, df, df]\n",
    "    dm = np.arange(N) + np.random.rand(N)\n",
    "    y = [dm, dm, dm]\n",
    "\n",
    "    stacked_interp = transform.InterpLongToWide(sample_period)\n",
    "    stacked_interp.fit(X, y)\n",
    "\n",
    "    Xc, yc, swt = stacked_interp.transform(X, y)\n",
    "\n",
    "    # --Checks--\n",
    "    assert Xc[0].shape[1] == len(np.unique(s)) * (X[0].shape[1]-2)\n",
    "    assert len(Xc[0]) <= N/sample_period\n",
    "\n",
    "    # Test 3 - duplicate entries for t\n",
    "    t = np.array([1.1, 1.1, 1.2, 2.1, 3.3, 3.4, 3.5]).astype(float)\n",
    "    s = np.array([0, 0, 1, 0, 0, 1, 1]).astype(float)\n",
    "    v1 = np.array([3, 3, 4, 5, 7, 15, 25]).astype(float)\n",
    "    v2 = np.array([5, 5, 7, 6, 9, 22, 35]).astype(float)\n",
    "    y = np.array([1, 1, 2, 2, 2, 3, 3]).astype(float)\n",
    "    df = np.column_stack([t, s, v1, v2])\n",
    "\n",
    "    X = [df, df]\n",
    "    y = [y, y]\n",
    "\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        stacked_interp = transform.InterpLongToWide(0.5, assume_sorted=False)\n",
    "        stacked_interp.fit(X, y)\n",
    "        Xc, yc, swt = stacked_interp.transform(X, y)\n",
    "\n",
    "        assert len(w) == 1\n",
    "        assert issubclass(w[-1].category, UserWarning)\n",
    "        assert \"duplicate\" in str(w[-1].message)\n",
    "\n",
    "        # --Checks--\n",
    "        assert len(Xc[0]) == 5\n",
    "        assert Xc[0].shape[1] == 4\n",
    "        assert swt is None\n",
    "        assert np.count_nonzero(np.isnan(Xc)) == 0\n",
    "\n",
    "\n",
    "def test_feature_rep_mix():\n",
    "    union = transform.FeatureRepMix([\n",
    "        ('a', transform.FeatureRep(features={'mean': mean}), 0),\n",
    "        ('b', transform.FeatureRep(features={'mean': mean}), 1),\n",
    "        ('c', transform.FeatureRep(features={'mean': mean}), [2,3]),\n",
    "        ('d', transform.FeatureRep(features={'mean': mean}), slice(0,2)),\n",
    "        ('e', transform.FeatureRep(features={'mean': mean}), [False, False, True, True]),\n",
    "    ])\n",
    "\n",
    "    # multivariate ts\n",
    "    X = np.random.rand(100, 10, 4)\n",
    "    y = np.ones(100)\n",
    "    union.fit(X, y)\n",
    "    Xt = union.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(union.f_labels) == Xt.shape[1]\n",
    "\n",
    "    # ts with multivariate contextual data\n",
    "    X = TS_Data(np.random.rand(100, 10, 4), np.random.rand(100, 3))\n",
    "    y = np.ones(100)\n",
    "    union.fit(X, y)\n",
    "    Xt = union.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(union.f_labels) == Xt.shape[1]\n",
    "\n",
    "    # ts with univariate contextual data\n",
    "    X = TS_Data(np.random.rand(100, 10, 4), np.random.rand(100))\n",
    "    y = np.ones(100)\n",
    "    union.fit(X, y)\n",
    "    Xt = union.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(union.f_labels) == Xt.shape[1]\n",
    "\n",
    "    # univariate ts\n",
    "    uni_union = transform.FeatureRepMix([\n",
    "        ('a', transform.FeatureRep(features={'mean': mean}), 0),\n",
    "        ('b', transform.FeatureRep(features={'mean': mean}), [0]),\n",
    "        ('c', transform.FeatureRep(features={'mean': mean}), slice(0,1)),\n",
    "        ('d', transform.FeatureRep(features={'mean': mean}), [True]),\n",
    "    ])\n",
    "    X = np.random.rand(100, 10)\n",
    "    y = np.ones(100)\n",
    "    uni_union.fit(X, y)\n",
    "    Xt = uni_union.transform(X)\n",
    "    assert Xt.shape[0] == len(X)\n",
    "    assert len(uni_union.f_labels) == Xt.shape[1]\n",
    "\n",
    "\n",
    "def test_function_transform():\n",
    "    constant = 10\n",
    "    identity = transform.FunctionTransformer()\n",
    "    def replace(Xt, value):\n",
    "        return np.ones(Xt.shape) * value\n",
    "    custom = transform.FunctionTransformer(replace, func_kwargs={\"value\": constant})\n",
    "\n",
    "    # univariate ts\n",
    "    X = np.random.rand(100, 10)\n",
    "    y = np.ones(100)\n",
    "\n",
    "    identity.fit(X, y)\n",
    "    Xtrans = identity.transform(X)\n",
    "    assert Xtrans is X\n",
    "\n",
    "    custom.fit(X, y)\n",
    "    Xtrans = custom.transform(X)\n",
    "    assert np.array_equal(Xtrans, np.ones(X.shape) * constant)\n",
    "\n",
    "    # multivariate ts\n",
    "    X = np.random.rand(100, 10, 4)\n",
    "    y = np.ones(100)\n",
    "\n",
    "    identity.fit(X, y)\n",
    "    Xtrans = identity.transform(X)\n",
    "    assert Xtrans is X\n",
    "\n",
    "    custom.fit(X, y)\n",
    "    Xtrans = custom.transform(X)\n",
    "    assert np.array_equal(Xtrans, np.ones(X.shape) * constant)\n",
    "\n",
    "    # ts with univariate contextual data\n",
    "    Xt = np.random.rand(100, 10, 4)\n",
    "    Xc = np.random.rand(100)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = np.ones(100)\n",
    "\n",
    "    identity.fit(X, y)\n",
    "    Xtrans = identity.transform(X)\n",
    "    assert Xtrans is X\n",
    "\n",
    "    custom.fit(X, y)\n",
    "    Xtrans = custom.transform(X)\n",
    "    Xtt, Xtc = get_ts_data_parts(Xtrans)\n",
    "    assert np.array_equal(Xtt, np.ones(Xt.shape) * constant)\n",
    "    assert Xtc is Xc\n",
    "\n",
    "    # ts with multivariate contextual data\n",
    "    Xt = np.random.rand(100, 10, 4)\n",
    "    Xc = np.random.rand(100, 3)\n",
    "    X = TS_Data(Xt, Xc)\n",
    "    y = np.ones(100)\n",
    "\n",
    "    identity.fit(X, y)\n",
    "    Xtrans = identity.transform(X)\n",
    "    assert Xtrans is X\n",
    "\n",
    "    custom.fit(X, y)\n",
    "    Xtrans = custom.transform(X)\n",
    "    Xtt, Xtc = get_ts_data_parts(Xtrans)\n",
    "    assert np.array_equal(Xtt, np.ones(Xt.shape) * constant)\n",
    "    assert Xtc is Xc\n",
    "\n",
    "    # test resampling\n",
    "    def resample(Xt):\n",
    "        return Xt.reshape(1, -1)\n",
    "\n",
    "    illegal_resampler = transform.FunctionTransformer(resample)\n",
    "    X = np.random.rand(100, 10)\n",
    "    y = np.ones(100)\n",
    "    illegal_resampler.fit(X, y)\n",
    "    with pytest.raises(ValueError):\n",
    "        Xtrans = illegal_resampler.transform(X)\n",
    "\n",
    "# MUST be defined in the global scope for pickling to work correctly\n",
    "def mock_resample(ndarray):\n",
    "    return ndarray[:len(ndarray) // 2]\n",
    "class MockImblearnSampler(BaseEstimator):\n",
    "    def __init__(self, mocked_param=\"mock\"):\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def _check_X_y(X, y):\n",
    "        return X, y, True\n",
    "    def fit_resample(self, X, y):\n",
    "        X, y, _ = self._check_X_y(X, y)\n",
    "        return mock_resample(X), mock_resample(y)\n",
    "\n",
    "def test_patch_sampler():\n",
    "    # test patch_sampler on a class without a fit_resample function\n",
    "    class EmptyClass(object):\n",
    "        pass\n",
    "    with pytest.raises(TypeError):\n",
    "        transform.patch_sampler(EmptyClass)\n",
    "\n",
    "    # test patch_sampler on a mocked imbalanced-learn Sampler class\n",
    "    unpatched_sampler = MockImblearnSampler()\n",
    "    patched_sampler = transform.patch_sampler(MockImblearnSampler)(shuffle=True, random_state=0)\n",
    "    assert str(patched_sampler.__class__) != str(unpatched_sampler.__class__)\n",
    "    pickled_sampler = pickle.dumps(patched_sampler)\n",
    "    unpickled_sampler = pickle.loads(pickled_sampler)\n",
    "    assert str(patched_sampler.__class__) == str(unpickled_sampler.__class__)\n",
    "\n",
    "    # test representation\n",
    "    assert \"mocked_param\" in repr(patched_sampler)\n",
    "    assert \"random_state\" in repr(patched_sampler)\n",
    "    assert \"shuffle\" in repr(patched_sampler)\n",
    "\n",
    "    # multivariate ts\n",
    "    X = np.random.rand(100, 10, 4)\n",
    "    y = np.ones(100)\n",
    "    Xt, yt, _ = patched_sampler.transform(X, y)\n",
    "    assert Xt is X\n",
    "    assert yt is y\n",
    "    Xt, yt, _ = patched_sampler.fit_transform(X, y)\n",
    "    X, y = shuffle(mock_resample(X), mock_resample(y), random_state=0)\n",
    "    assert np.array_equal(Xt, X)\n",
    "    assert np.array_equal(yt, y)\n",
    "\n",
    "    # ts with multivariate contextual data\n",
    "    X = TS_Data(np.random.rand(100, 10, 4), np.random.rand(100, 3))\n",
    "    Xt_orig, _ = get_ts_data_parts(X)\n",
    "    y = np.ones(100)\n",
    "    Xt, yt, _ = patched_sampler.transform(X, y)\n",
    "    assert Xt is X\n",
    "    assert yt is y\n",
    "    Xt, yt, _ = patched_sampler.fit_transform(X, y)\n",
    "    Xtt, Xtc = get_ts_data_parts(Xt)\n",
    "    Xt_orig, y = shuffle(mock_resample(Xt_orig), mock_resample(y), random_state=0)\n",
    "    assert np.array_equal(Xtt, Xt_orig)\n",
    "    assert np.array_equal(yt, y)\n",
    "\n",
    "    # ts with univariate contextual data\n",
    "    X = TS_Data(np.random.rand(100, 10, 4), np.random.rand(100))\n",
    "    Xt_orig, _ = get_ts_data_parts(X)\n",
    "    y = np.ones(100)\n",
    "    Xt, yt, _ = patched_sampler.transform(X, y)\n",
    "    assert Xt is X\n",
    "    assert yt is y\n",
    "    Xt, yt, _ = patched_sampler.fit_transform(X, y)\n",
    "    Xtt, Xtc = get_ts_data_parts(Xt)\n",
    "    Xt_orig, y = shuffle(mock_resample(Xt_orig), mock_resample(y), random_state=0)\n",
    "    assert np.array_equal(Xtt, Xt_orig)\n",
    "    assert np.array_equal(yt, y)\n",
    "\n",
    "    # univariate ts\n",
    "    X = np.random.rand(100, 10)\n",
    "    y = np.ones(100)\n",
    "    Xt, yt, _ = patched_sampler.transform(X, y)\n",
    "    assert Xt is X\n",
    "    assert yt is y\n",
    "    Xt, yt, _ = patched_sampler.fit_transform(X, y)\n",
    "    X, y = shuffle(mock_resample(X), mock_resample(y), random_state=0)\n",
    "    assert np.array_equal(Xt, X)\n",
    "    assert np.array_equal(yt, y)\n",
    "    \n",
    "test_patch_sampler()\n",
    "test_function_transform()\n",
    "test_feature_rep_mix()\n",
    "#test_interp_long_to_wide()\n",
    "test_interp()\n",
    "test_pad_trunc()\n",
    "test_segmentxyforecast()\n",
    "test_segmentxy()\n",
    "test_segmentx()\n",
    "test_sliding_tensor()\n",
    "test_sliding_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error in one of the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Desktop\\WB1 WB1\\HM1.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_interp_long_to_wide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\WB1 WB1\\HM1.ipynb\u001b[0m in \u001b[0;36mtest_interp_long_to_wide\u001b[1;34m()\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[0mXc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacked_interp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;34m\"duplicate\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_interp_long_to_wide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: David Burns\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from seglearn.datasets import load_watch\n",
    "from seglearn.base import TS_Data\n",
    "from seglearn import util\n",
    "\n",
    "\n",
    "def test_util():\n",
    "    df = load_watch()\n",
    "\n",
    "    data = TS_Data(df['X'], df['side'])\n",
    "    Xt, Xc = util.get_ts_data_parts(data)\n",
    "\n",
    "    assert np.array_equal(Xc, df['side'])\n",
    "    assert np.all([np.array_equal(Xt[i], df['X'][i]) for i in range(len(df['X']))])\n",
    "\n",
    "    util.check_ts_data(data, df['y'])\n",
    "    util.check_ts_data(df['X'], df['y'])\n",
    "\n",
    "    util.ts_stats(df['X'], df['y'], fs=1., class_labels=df['y_labels'])\n",
    "\n",
    "\n",
    "def test_to_categorical_series():\n",
    "    p = np.arange(10)\n",
    "    step = 2\n",
    "    width = 3\n",
    "    s = util.segmented_prediction_to_series(p, step, width, categorical_target=True)\n",
    "    assert len(s) == (len(p) - 1) * step + width\n",
    "    assert np.all(np.isin(s, p))\n",
    "\n",
    "    p = np.arange(10)\n",
    "    step = 3\n",
    "    width = 2\n",
    "    s = util.segmented_prediction_to_series(p, step, width, categorical_target=True)\n",
    "    assert len(s) == (len(p) - 1) * step + width\n",
    "    assert np.all(np.isin(s, p))\n",
    "\n",
    "    p = np.arange(10)\n",
    "    p = np.column_stack([p, p])\n",
    "    step = 2\n",
    "    width = 3\n",
    "    s = util.segmented_prediction_to_series(p, step, width, categorical_target=True)\n",
    "    assert len(s) == (len(p) - 1) * step + width\n",
    "    assert s.shape[1] == 2\n",
    "    assert np.all(np.isin(s, p))\n",
    "\n",
    "def test_to_real_series():\n",
    "    p = np.arange(20)  # highly overlapping case\n",
    "    step = 2\n",
    "    width = 5\n",
    "    s = util.segmented_prediction_to_series(p, step, width, categorical_target=False)\n",
    "    assert len(s) == (len(p) - 1) * step + width\n",
    "    assert np.all(s <= max(p))\n",
    "    assert np.all(s >= min(p))\n",
    "\n",
    "    p = np.arange(10)\n",
    "    step = 3\n",
    "    width = 2\n",
    "    s = util.segmented_prediction_to_series(p, step, width, categorical_target=False)\n",
    "    assert len(s) == (len(p) - 1) * step + width\n",
    "    assert np.all(s <= max(p))\n",
    "    assert np.all(s >= min(p))\n",
    "\n",
    "    p = np.arange(5)\n",
    "    p = np.column_stack([p, p])\n",
    "    step = 2\n",
    "    width = 5\n",
    "    s = util.segmented_prediction_to_series(p, step, width, categorical_target=False)\n",
    "    assert len(s) == (len(p) - 1) * step + width\n",
    "    assert s.shape[1] == 2\n",
    "    assert np.all(s <= np.max(p))\n",
    "    assert np.all(s >= np.min(p))\n",
    "    \n",
    "    \n",
    "test_util()\n",
    "test_to_categorical_series()\n",
    "test_to_real_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the article is preety much fully reproducible, except of the some example. One of them is connected with the other packages in python. One of the test is not passed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
